---
title: "Final Group Project: AirBnB analytics"
date: "12 Oct 2021"
author: "Reading Time: About 8 minutes"
output:
  html_document:
    highlight: zenburn
    theme: flatly
    toc: yes
    toc_float: yes
    number_sections: yes
    code_folding: show
---


```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


```{r load-libraries, echo=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)
library(car)
```


# Introduction

In our final group assignment we are going to analyse data about Airbnb listings and fit a model to predict the total cost for two people staying 4 nights in an AirBnB in a city. We have chosen Amsterdam for our analysis. 

Our AirBnB data come from [insideairbnb.com](http://insideairbnb.com/get-the-data.html){target="_blank"}; it was originally scraped from airbnb.com. 

Below we load the data from Airbnb:

```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

#Load the data

listings <- vroom("http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-09-07/data/listings.csv.gz") %>% 
       clean_names()

```

MAKE SURE ALL OF THESE ARE ANSWERED:

- How many variables/columns? How many rows/observations?
- Which variables are numbers?
- Which are categorical or *factor* variables (numeric or character variables with variables that have a fixed and known set of possible values?
- What are the correlations between variables? Does each scatterplot support a linear relationship between variables? Do any of the correlations appear to be conditional on the value of a categorical variable?

# Exploratory Data Analysis (EDA)

##Data overview
We use `glimpse` and `skim` to gain a general view of the data. We have 74 variables and 16,116 observations. Variables include 24 character variables, 5 date variables, 8 logical variables, and 37 numeric variables. We also have some missing values throughout multiple of the variables in our data. 

```{r}
#Overview of Data
glimpse(listings)
skim(listings)

```

First out of interest we would like to plot a map of the raw dataset. 

By plotting a cluster map that shows the number of flat listed for rent, we want to visualise the concentration of listings in the area of Amsterdam

```{r}
#Map the concentration of listing in Amsterdam
listings %>% 
  leaflet() %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1,
                   fillOpacity = 0.3, 
                   popup = ~listing_url,
                   label = ~property_type,
                   clusterOptions = markerClusterOptions()
                   )
```

From this map, we concluded that more properties are available in the central area of Amsterdam. We would like to further investigate the relationship between the price of listings and the locations of properties.

We select some variables for our analysis which we believe would be relevant to determine the impact on prices.


We will hypothesize that the following are key variables which will will be using later on 

- `price` = cost per night (variable we will be use to predict)
- `property_type`: type of accommodation (House, Apartment, etc.)
- `room_type`:

  - Entire home/apt (guests have entire place to themselves)
  - Private room (Guests have private room to sleep, all other rooms shared)
  - Shared room (Guests sleep in room shared with others)

- `number_of_reviews`: Total number of reviews for the listing
- `review_scores_rating`: Average review score (0 - 100)
- `neighbourhood*`: three variables on a few major neighbourhoods in each city 
- `Host_since`: How the long the host has been on Airbnb
- `accomodations`: How many people can stay in the room per night
- `beds`: Number of beds
- `host_is_superhost`: Whether the host has superhost status
- `minimum_nights`: Minimum nights to stay in the Airbnb
- `bedrooms`: Number of bedrooms
- `reviews_per_month`: Number of reviews per month
- `availability_30`: Available stays next 30 days
- `last_review`: Last review date
- `license`: license number
- `instant_bookable`: Whether the room can be instantly booked

If you are interest in further information is is available [here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896)

Let's first filter for our variables of interest

```{r}

#Select the variables for further exploration

listings2 <- listings %>% 
  
  select(c("host_since", 
           "host_is_superhost", 
           "neighbourhood_cleansed", 
           "property_type", 
           "room_type", 
           "accommodates",
           "price",
           "review_scores_rating", 
           "number_of_reviews",
           "minimum_nights", 
           "reviews_per_month",
           "bedrooms","beds",
           "availability_30",
           "last_review",
           "license",
           "instant_bookable"))

# We want to choose the "bathrooms" as well, however,this variable has no values

```

## Data wrangling

Now let's ensure we can work with our data. 

First lets briefly look at our new dataset

```{r}
skim(listings2)
```


We see some issues that we will try and resolve. 


### Price

First:

Price is sometimes given as a character string and we would like it to be a double variable. 

Below we change the price to a double, i.e. a numeric variable. 

```{r}
#Change the 'price' to numeric
listings2 <- listings2 %>% 
  mutate(price = parse_number(price))

#Use `typeof(listing2$price)` to confirm that `price` is now stored as a number.
typeof(listings2$price)

```


### Licenses 

We then want to impute the missing value of "license" with logical judgement instead of a license number.

This will make our analysis simply focus on whether people have a license or not. 

```{r}
#Impute the missing value of “license”
listings2<-listings2 %>% 
  
  #Add yes or no depending on whether variable is missing
  mutate(license = ifelse(is.na(license), "no","yes"))


#Let's check our data by filtering for our license
License_check <- listings2 %>% 
  select(license)


#Let's take a glimpse at the results.
glimpse(License_check)

```

The code works as hoped. 


### Property types

Next, we look at the variable `property_type`. We use the `count` function to determine how many categories there are and their frequency.

This will be useful later to summarize our property types in larger categories as there will be more observations and less variables in the regression. 


```{r}
#Determine how many categories there are and their frequency
count_prop <- listings2 %>% 
  
  #Select variable of interest - i.e. property types
  select(property_type) %>% 
  
  #Count Number of each property type
  count(property_type) %>% 
  
  #Arrange by most frequent category
  arrange(desc(n)) %>% 
  
  #Create a new column for proportions
  mutate(percentage=n/sum(n)*100) #Determine the proportion of the total listings the top 4 types make up 

#Print Table
count_prop

```


The top 4 common property types are "Entire rental unit","Private room in rental unit","Entire residential home" and "Entire townhouse". The top 4 types make up 60.66%, 11.48%, 6.48%, and 2.66% of the total listings


This will also make it easier for our regressions at a later stage given this is categorical variables.

```{r}
#Simplify the "property_type" 
listings2 <- listings2 %>%
  
  #Create new names called other for properties not in the top four categories
  mutate(prop_type_simplified = case_when(
    
    #Specifying names to be kept
    property_type %in% c("Entire rental unit",
                         "Private room in rental unit", 
                         "Entire residential home",	
                         "Entire townhouse") ~ property_type, 
    
    #Specifying ot leave remaining in other
    TRUE ~ "Other"))

#We check the `prop_type_simplified` was correctly made
listings2 %>%
  
  #Count each category
  count(property_type, prop_type_simplified) %>%
  
  #Arrange by largest category
  arrange(desc(n))    

#Removing the old property type
listings2 <- subset(listings2, select = -property_type)
  
```


Our table comes out as expected and we can see that all smaller property types are in the other category. 


### Neighbourhood

Next, we look at the variable `neighbourhood_cleansed`. We use the `count` function to determine how many categories there are and their frequency. 
The top 5 common neighbourhoods are "De Baarsjes - Oud-West","De Pijp - Rivierenbuurt","Centrum-West", "Centrum-Oost" and "WesterPark". The top 5 types make up 18.0%, 12.14%, 10.75%, 8.17%%, and 7.79% of the total listings

```{r}
#Determine how many categories there are and their frequency
count_prop <- listings2 %>% 
  
  #Selecting variable of interest
  select(neighbourhood_cleansed) %>% 
  
  #Counting observations 
  count(neighbourhood_cleansed) %>% 
  
  #Arrange by observations
  arrange(desc(n)) %>% 
  
  #In Percentage
  mutate(percentage=n/sum(n)*100) #Determine the proportion of the total listings the top 4 types make up 

#Print Table
count_prop

```

Looking into this we see that there are many more high observation neighbourhoods compared to property types.

Therefore, we believe it makes more sense to split the neighbourhood by their relative prices. 

We do this below


```{r}
#Setting neighbourhood by price
neighbourhood_group <- listings2 %>% 
  
  #Variable of interest
  group_by(neighbourhood_cleansed) %>% 
  
  #Getting median price
  summarize(price_median = median(price)) %>% 
  
  #Arranging by highest price
  arrange(desc(price_median))

#Print
neighbourhood_group


```

We see that some central neighbourhoods are more expensive, which logically makes sense given this is a large city and that is where tourists and other activities are. 

Let's categorize neighbourhood by price

```{r}
#Simplify the "property_type" 
listings2 <- listings2 %>%
  
  #Adding new variable names
  mutate(neighbourhood_cleansed = case_when(
                                  neighbourhood_cleansed == "Centrum-Oost" ~ "Top 5",
                                  neighbourhood_cleansed == "Centrum-West" ~ "Top 5",
                                  neighbourhood_cleansed == "IJburg - Zeeburgereiland" ~ "Top 5",
                                  neighbourhood_cleansed == "Zuid" ~ "Top 5",
                                  neighbourhood_cleansed == "De Pijp - Rivierenbuurt" ~ "Top 5",
                                  neighbourhood_cleansed == "Oud-Noord" ~ "Top 6-10",
                                  neighbourhood_cleansed == "Watergraafsmeer" ~ "Top 6-10",
                                  neighbourhood_cleansed == "Oud-Oost" ~ "Top 6-10",
                                  neighbourhood_cleansed == "Westerpark" ~ "Top 6-10",
                                  neighbourhood_cleansed == "De Baarsjes - Oud-West" ~ "Top 6-10",
                                  neighbourhood_cleansed == "Noord-West" ~ "Top 11-15",
                                  neighbourhood_cleansed == "Noord-Oost" ~ "Top 11-15",
                                  neighbourhood_cleansed == "Oostelijk Havengebied - Indische Buurt" ~ "Top 11-15",
                                  neighbourhood_cleansed == "Buitenveldert - Zuidas" ~ "Top 11-15",
                                  neighbourhood_cleansed == "Bos en Lommer" ~ "Top 11-15",
                                  neighbourhood_cleansed == "Geuzenveld - Slotermeer" ~ "Remaining",
                                  neighbourhood_cleansed == "Slotervaart" ~ "Remaining",
                                  neighbourhood_cleansed == "De Aker - Nieuw Sloten" ~ "Remaining",
                                  neighbourhood_cleansed == "Osdorp" ~ "Remaining",
                                  neighbourhood_cleansed == "Gaasperdam - Driemond" ~ "Remaining",
                                  neighbourhood_cleansed == "Bijlmer-Centrum" ~ "Remaining",
                                  neighbourhood_cleansed == "Bijlmer-Oost" ~ "Remaining"))
                                  
                                
#Check the `prop_type_simplified` was correctly made
listings2 %>%
  
  #Counting by number of observations
  count(neighbourhood_cleansed) %>%
  
  #Displaying in descending order
  arrange(desc(n))    

```


### Minimum nights

Let's first look into how minimum nights look at Airbnb Amsterdam. 

```{r}
#Find out the most common values for the variable `minimum_nights`
listings2 %>%
  
  #Count Observations
  count(minimum_nights) %>%
  
  #Arrange by observations
  arrange(desc(n))

```


By looking into the vairable `minimum_nights`, we found out that airbnb most commonly required people to stay for at least 2 nights. The majority of users tend to spend less than a week, which indicates that Airbnb is most commonly used for travel purposes, i.e., as an alternative to traditional hotels.. 

There are also some variables that stand out i.e. minimum nights of 1,100 days (3 years minimum rent)

We only want to include listings in our regression analysis that are intended for travel purposes, i.e. no more than 4 days.

```{r}
#Filter the Airbnb data so that it only includes observations with `minimum_nights <= 4`
listings2 <- listings2 %>% 
  filter(minimum_nights <= 4)

```


### Dropping NA's 

We then skim the dataset to see if further data wrangling is required.

```{r}
skim(listings2)
```

As we can see, review_scores_rating, reviews_per_month, host_is_superhost, bedrooms and beds still have missing values. We will drop unreviewed units for now and as these units will likely be less accurate in terms of price / review ratings. Similarly for bedrooms and beds, we drop missing values.

```{r}
#Dropping values

listings2 <-  listings2 %>% 
  
  #Choosing which variables to drop NAs from
  drop_na(bedrooms,beds,host_is_superhost,review_scores_rating,reviews_per_month)

#Skimming to confirm code works as intended. 
skim(listings2)
```

### Dropping Rating 0 

We also know that ratings on Airbnb are 1-5, therefore there must be an issue with reviews that are 0 out of 5. 

Let's remove these from our data

```{r}

#Dropping reviews at 0
listings2 <- listings2 %>% 
  filter(review_scores_rating > 0)

```


### Final skim of data

Let's take a final skim of the data

```{r}
skim(listings2)
```



We now have wrangled our data sufficiently and have:
- 4 character variables ready for analysis with not too many categories.
- 2 Date variables with no missing values
- 2 Logical variables with no missing variables
- 9 range of numeric variables with no missing values. 


We also have 11.4 thousand observations. 

We will now explore how these variables affect price.

## Visualisations
By visualising the relationship between price and the variables that we believe will affect the price substantially, we hope to identify a noticeable correlation between price and each of those variables and use statistical modelling to further investigate their relationships and provide possible explanation.

### Overview of Price
We first take a look at the price. 

```{r}
#Overview of price
favstats(listings2$price)
```

We see that price ranges from 4 to 8,000 per night with a mean of 154 and median of 130 (i.e. some left skew)

We create the density plot of price.

```{r}

#Create a density plot of prices
ggplot(listings2,aes(x=price))+
  
  #Using a density plot
  geom_density()+
  
  #Adding useful titles
  labs(title="Density plot of listing Airbnb prices",
       x="Price",
       y="Density") + 
  
  #Minimal theme
  theme_minimal()



#Create a density plot of log of prices
ggplot(listings2,aes(x=log(price)))+
  
  #Density plot
  geom_density()+
  
  #Useful Labes
  labs(title="Density plot of listing Airbnb (log) prices",
       x="Log Price",
       y="Density") + 
  
  #Minimal Theme
  theme_minimal()
```

From here forward we will use Log which is more normally distributed. We can see that there are some peaks and lows on the graph which we connect to well-known disposition of people to round numbers, i.e. setting price to be USD 140 instead of USD 137 or  USD 142. We assume that the graph would be smooth and almost perfectly normally distributed without this feature




### Location/ Neighbourhood

First, we skimmed the neighbourhood_cleansed data to analyse the distribution of price of listings depends on neighbourhood. 
From the table below,  we found out that median price will better suits the purpose of our research than the mean price because the distribution of price of each neighbourhood is greaatly skewed with extreme outliers.For example all neighbourhoods have lower median than mean price while the most expensive property costs USD8000, causing a large standard deviation. Hence, standard deviation is unusually large among neighbourhood

```{r}
#Analyse the distribution of price of listings depends on neighbourhood
favstats(price~neighbourhood_cleansed,data=listings2) %>% 
  
  #Arrange by count
  arrange(desc(n)) 

```

We then plot a density graph to see the price distribution of the most popular neighbourhood.

```{r}


#Create the dataset of the top neighbourhood and the price
listings_neigh<-listings2 %>% 
  
  #Group by variable we are looking at
  group_by(neighbourhood_cleansed) %>% 
  
  #ANd get the price
  summarize(price=price)

listings_neigh$new <- factor(listings_neigh$neighbourhood_cleansed, levels = c("Top 5", "Top 6-10", "Top 11-15", "Remaining"))

#Plot the density graph
ggplot(listings_neigh,aes(x=log(price), y = desc(new), fill = new))+
  
  #Density Ridges Plit
  geom_density_ridges(alpha=0.3) +    
  
  #Useful lables
  labs(      
      title = "Difference in price by region expensiveness",
      subtitle="Density plot for prices in different region groups",
      x = "Price per night (log)",
      y = "Density") + 
      theme_classic() + 
  
  #Title of Legend
  guides(fill=guide_legend(title="Neighbourhood regions"))+ 
  
  #Plotting a vertical line at the median
  geom_vline(xintercept = median(log(listings2$price)), colour = "#001e62")+
  NULL


```

The graph shows that the neighbourhoods vary in price and will likely be a good predictor for our analysis later on. 

Let's look at the median price by neighbourhood as well: 


```{r}
#Calculate the median price of different neighborhood
median_per_neighborhood <- listings2 %>% 
  
  #Grouping by variable
  group_by(neighbourhood_cleansed) %>% 
  
  #We want median price
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_neighborhood,
       
       #Price versus neighbourhood
       aes(x = reorder(neighbourhood_cleansed, median_price),
           y= median_price)) +
  
  #Columns chart
  geom_col(fill = "skyblue") +
  
  #USeful labes
  labs(
    title = "Median price per night per Neighborhood",
    x="Neighborhood",
    y="Median Price"
    ) +
  
  #To flip axis
  coord_flip() +
  
  #Simple theme
  theme_bw() +
  NULL

```

Plotting on a median price basis indicates that these prices are still indeed impacted by how close they are to center.

### Number of Bedrooms
We skimmed our data to summarise the price distribution based on number of bedrooms. 

From the table below, we noticed that listings with more than five bedrooms have less than 10 samples, therefore, we decided to only include properties with up to five bedrooms. Furthermore, we found out that median price will better suit the purpose of our research than the mean price because the distribution of price based on number of bedrooms is greatly skewed due to extreme outliers. Therefore, we believe that the median price gives better understanding of the relationship between the price and the number of bedrooms

```{r}
#Analyse the distribution of price of listings depends on number of bedrooms
favstats(price~bedrooms, data=listings2)

```
The graph shows that the listings having more bedrooms have a higher median price.

```{r}
#Filter the bedrooms under 5 for further discussion

listings2 <- listings2 %>% 
  filter(bedrooms<=5)

median_per_bedroom <- listings2 %>% 
  group_by(bedrooms) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_bedroom,
       aes(x = reorder(bedrooms,median_price),
           y= median_price)) +
  geom_col(fill = "orchid3") +
  labs(
    title = "Median price per night per bedrooms",
    x="Number of Bedrooms",
    y="Median Price"
    ) +
  theme_bw() +
  NULL
```

### Ratings 
We skimmed our data to summarise the price distribution based on the rating score.

```{r}
#Analyse the distribution of price of listings depends on the rating score
favstats(price~review_scores_rating,data=listings2)
```

By drawing a regression line between the median price and the ratings, we concluded that they share a positive correlation, which means higher ratings have higher median price, and vice versa.

```{r}
##Create the data of price and score rating
median_per_rating <- listings2 %>% 
  group_by(review_scores_rating) %>% 
  summarise(median_price = median(price)) %>% 
  na.omit()


ggplot(median_per_rating,
       aes(x = review_scores_rating,
           y= median_price)) +
  geom_point(color="red") +
  labs(title = "Median price per night vs. Ratings",
    x="Ratings",
    y="Median Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  NULL


```

Additional chart. 

```{r}
ggplot(listings2, aes(x = review_scores_rating, y = log(price))) + 
  geom_point(color = "red") + 
  geom_smooth(se = F, method = "lm", color = "black") + 
  theme_bw()
```


We further find out that superhost has higher rating than non superhost by coloring the below above graph by host type.

```{r}
#Create the data of price, score rating, and superhost
median_per_rating1 <- listings2 %>% 
  group_by(review_scores_rating) %>% 
  summarise(median_price = median(price),
            host_is_superhost=host_is_superhost) %>% 
  na.omit()


ggplot(median_per_rating1,
       aes(x = review_scores_rating,
           y= median_price)) +
  geom_point(aes(colour = host_is_superhost)) +
  labs(title = "Median price per night vs. Ratings",
    x="Ratings",
    y="Median Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  guides(fill=guide_legend(title="Host is Superhost"))+
  facet_wrap(~host_is_superhost)
  
  NULL

```


Similarly we can graph a relationship between number of reviews and price

```{r}
ggplot(listings2, 
       aes(x = number_of_reviews,
           y= log(price))) +
  geom_point(color="red") +
  labs(title = "Price per night vs. number of Reviews",
    x="Number of Reviews",
    y="Log Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  NULL
```

WE see that as the number of reviews increase the price falls, likely because these are less premium properties. 

### License 
We want to find out the relationship between license and price of linceses. By graphing a boxplot, we see that properties with license have higher Q1, median and Q3 value than properties without license. Hence, we conclude that properties with licence are more expensive than the others.

```{r}
listing2_low_price <- listings2 

ggplot(listing2_low_price,aes(x=license,y=log(price)))+
  geom_boxplot(fill="wheat2")+
  labs(title = "Price per night vs. License",
    x="License",
    y=" Price"
    )+
  theme_bw()

```
We see that there is a higher spread on prices of properties without licenses and a slightly lower average. 


### Room type

```{r}
#Calculate the median price of different room types
median_per_room <- listings2 %>% 
  group_by(room_type) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_room,
       aes(x = reorder(room_type, median_price),
           y= median_price)) +
  geom_col(fill = "skyblue") +
  labs(
    title = "Median price by room_type",
    x="Room Type",
    y="Median Price"
    ) +
  coord_flip() +
  theme_bw() +
  NULL
```
We see that entire homes and hotel rooms are especially expensive. We can also plot the density of this




```{r}
#Create the dataset of the top Room type and the price
listings_room<-listings2 %>% 
  group_by(room_type) %>% 
  summarize(price=price)

#Plot the density graph
ggplot(listings_room,aes(x=log(price),fill = room_type))+
  geom_density(alpha=0.3) +    
  labs(      
      title = "Price distribution in room types",
      subtitle="Density plot for prices in different room types",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
  guides(fill=guide_legend(title="Room types"))+
  facet_wrap(~room_type, ncol = 1) + 
  NULL


```
Interestingly although entire homes or apartments are the most expensive in terms of median, we see that some hotels are also extremely expensive.



### Property Type

```{r}
#Calculate the median price of different room types
median_per_prop <- listings2 %>% 
  group_by(prop_type_simplified) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_prop,
       aes(x = reorder(prop_type_simplified, median_price),
           y= median_price)) +
  geom_col(fill = "skyblue") +
  labs(
    title = "Median price by property type",
    x="Room Type",
    y="Median Price"
    ) +
  coord_flip() +
  theme_bw() +
  NULL
```

### Avaialability next 30 days

```{r}
listings_availability<-listings2 %>% 
  group_by(availability_30) %>% 
  summarize(price=median(price))


ggplot(listings_availability, 
       aes(x = availability_30,
           y= log(price))) +
  geom_point(color="red") +
  labs(title = "Median Price Per Night versus Availability",
    x="Availability next 30 days",
    y="Log Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  NULL
```
Interestingly the more availability the higher the price indicating that more premium rooms are booked less often or are less often fully booked. 


### Instant Bookable

Last but nost least we will look at whether or not units are instantly bookable

```{r}

ggplot(listings2,aes(x=instant_bookable,y=log(price)))+
  geom_boxplot(fill="wheat2")+
  labs(title = "Distribution of whether or not units are instantly bookable",
    x="Instantly Bookable",
    y="Log Price"
    )+
  theme_bw()

```
There seems to be little to no difference between whether or not the units are bookable 


### Paired relationship overview
We plotted a GG pairs plot to get a comprehensive overview of the relationship between the price of listings and the selected variables. 

```{r}
##Problem: 1. what variables to choose? 2.Do we need further explanation for this part?

#DME Comment - i think we should do a bunch to all
```


```{r}
#Relatonship between the price and variables, starting with numerical variables
listings2 %>% 
  select(price,accommodates, review_scores_rating, number_of_reviews, minimum_nights, reviews_per_month, bedrooms, beds, availability_30) %>% 
  ggpairs(aes(alpha=0.2))+
  theme_minimal(base_size=8)

```
From the above we see that for price the most correlated variables is the number of accomodates or bedrooms (although these are  correlated with 0.73 and will likely not both be included). However, from here it seems that oerhaps it is better to focus on accommodates rather than bedrooms. 

Unfortunately, GGPairs does not work well with categorical variables and we will use that data we extracted above as an indicator for whether or not these variables will be useful going forward
`

# Regression Analysis
For the target variable $Y$, we will use the cost for two people to stay at an Airbnb location for four (4) nights. 
We first create a new variable called `price_4_nights` that uses `price`, and `accomodates` to calculate the total cost for two people to stay at the Airbnb property for 4 nights. This is the variable $Y$ we want to explain.


We assume that this leaves us with Airbnbs accommodating 2 or more people. I.e. we filter out Airbnb's which accomodate 1 person. 

Also, we assume that no other people would go to the airbnb lowering the cost per person (i.e. 2 people could rent a 10 people Airbnb but would be the only two to pay)

```{r}
##Fist, we have to filter the data to represent 2 people staying for 4 nights.
listings_4 <- listings2 %>% 
  filter(accommodates>=2) %>% 
  mutate(price_4_nights =price*4)

```

We take logarithm of ’price_4_nights‘ and create the density plot, because it looks more like the normal distribution

```{r}
#Unvertain answer: Use histograms or density plots to examine the distributions of `price_4_nights` and `log(price_4_nights)`. Which variable should you use for the regression model? Why?
```


```{r}
# Plot density of price using price_4_nights
ggplot(listings_4,aes(x=price_4_nights))+
  geom_density() +    
  labs(      
      title = "Density plot for prices for 4 nights",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
    NULL

# Plot density of price using log(price_4_nights)
ggplot(listings_4,aes(x=log(price_4_nights)))+
  geom_density() +    
  labs(      
      title = "Density plot for prices for 4 nights",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
    NULL
```

We see that taking the log of prices brings us much closer to a normal distribution why we use log prices going forward. 


## Model1: property type, number of reviews and the rating scores
We first fit a regression model with the following explanatory variables: `prop_type_simplified`, `number_of_reviews`, and `review_scores_rating`. 


First, let us split the data into a training and testing set. The training will be used for the models


```{r}
set.seed(123456)

train_test_split <- initial_split(listings_4, prop = 0.75)
listings_train <- training(train_test_split)
listings_test <- testing(train_test_split)
```


```{r}

#Create the model1
model1 <- lm(log(price_4_nights) ~ prop_type_simplified +number_of_reviews +review_scores_rating ,data=listings_train)
summary(model1)

```


We come to an adjusted R squared of 0.169 which is a good start. We see that all variables have significant t-values indicating they are significantly different from 0. 

Also, We see that some room types (such as entire residential home or townhouse willa dd to the price and other and private room will lower the price)

More specifically these values changes as units changed compared to the unit left out ()

- Entire residential home increases log of price 0.2 
- Entire Townhouse increases log of price 0.28
- Other  decreases log of price 0.007
- Private room decreases log of price 0.53

These numbers are compared to if the unit is entire rental Unit which is the variable excluded (Categorical Variables exclude one variable)



These variables are compared to whether or not the unit is 


For review scores rating we see that as rating goes up 1 unit log of price goes up 0.019. 

However, as number of reviews goes up price goes down. For every 100 additional reviews price falls roughly 0.05 (Likely because those properties are less premium).


## Room Type
Now lets add the room type

```{r}
#Create the model1
model2 <- lm(log(price_4_nights) ~ prop_type_simplified +number_of_reviews +review_scores_rating + room_type ,data=listings_train)
summary(model2)
```
Our model now explains slightly more butsome variables are no longer significant.

Specificallywe see that hotel rooms, private rooms and shared rooms all lower the price compared to entire home/apt. 

Lets now test for VIF given our model has some p-value issues:

```{r}
car::vif(model2)
```
Let's keep the variables in 



## Model 3: Bedrooms, beds and accomodates
We want to further determine whether the number of`bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`.

WE surprisingly see that VIF is not too high between beds, bedrooms, and accomodates so we keep them in for now. We will now include beds, because it is insignificant. 

We do see that these factors explain quite well the price changes and has an Rsquare of 0.2818. Lets add it to our model

```{r}


model3_1 <- lm(log(price_4_nights) ~ prop_type_simplified+number_of_reviews+review_scores_rating + beds +  room_type+bedrooms + accommodates, data = listings_4)

```

```{r}
summary(model3_1)
```
Once again we get a higher R Square but some of these variables are no longer significant. 

Let's check VIF

```{r}
vif(model3_1)
```
WE now see quite a high variance inflation factor for Prop_type_simplified, and Room Type. This makes sense as the room type (i.e. hotel room) is related to property type (i.e. a hotel)

Let's try and run and see each model without one another. 

```{r}
###
model3_3 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates, data = listings_4)
model3_4 <- lm(log(price_4_nights) ~ prop_type_simplified+number_of_reviews+review_scores_rating + bedrooms + accommodates, data = listings_4)

vif(model3_3)
vif(model3_4)


```

We immidieatly lower our variance inflation factor. 

Now let's try and decide which model is stronger going forward. 

```{r}
summary(model3_3)
summary(model3_4)
```
We see that model 3_3 (room type) provides better explanatory power than 3_4 (property type), and will utilize that going forward. 


### Model4: Superhosts
We want to explore whether the superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables. 

First let us look at superhosts on a standalone basis 

```{r}
model4_1 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost, data = listings_4)
summary(model4_1)

```

The variable is significant however, it only has very little explanatory power. Let's try and compute the VIF once again to check out model


> DME comment, i am uncertain when we should take out non-significant variables and when to run the test (splitting the data)



```{r}
vif(model4_1)
```
We see that VIF is below 5 for all variables meaning the variables do not have too high correlation

### Model 5, Immidiate bookings

1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?

```{r}
model5_1 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost + instant_bookable, data = listings_4)
summary(model5_1)

```

Here we see instant bookable is a significant predictor which will can be used in our model. 

We once again control VIF
```{r}
vif(model5_1)

```
Still these factors are not correlated enough for us to be worried. 


### Neighboughoods 

For this section we have not chosen the neighbourhood_overview variables as it had a lot of NAs. 

```{r}
model6_1 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost + instant_bookable + neighbourhood_cleansed, data = listings_4)
summary(model6_1)
```

We see that neighbourgood categorization is a really impactful driver on our prices. 

Testing VIF
```{r}
vif(model6_1)
```
Still VIF looks fine.


### Availability

Next lets look at availability in the coming 30 days

```{r}
model7_1 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost + instant_bookable + neighbourhood_cleansed + availability_30, data = listings_4)
summary(model7_1)
```

Once again, this variable is a significant explanatory variable. Let's test for VIF once again:

```{r}
vif(model7_1)
```

All VIFS are low and therefore we make no changes.

### License

```{r}
model_final <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost + instant_bookable + neighbourhood_cleansed + availability_30 + license, data = listings_4)
summary(model_final)
```


License is indeed a significant predictor of price

```{r}
vif(model_final)
```




## Diagnostics, collinearity, summary tables

Final VIF

```{r}
vif(model_final)
```


Variance inflation factor is below 5 for all variables. 

```{r}
autoplot(model_final)
```
For our model we see that resudual errors are evenly distributed and do not change as the variable fitted values change. This is a good sign for our model.

Futhermore we see from the theoretical quantiles that our model is approximately evenly distributed but not 100% evenly distributed. 

As you keep building your models, it makes sense to:



1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.




Given the above, it seems both beds and license can be removed without any material effect. 

Final Table


```{r}
huxreg(list("Prop Type, Reviews, Rating" = model1, "+ Room Type" = model2, "+ Beds + Bedrooms + Accom." = model3_1, "- Prop Type" = model3_3, " - Room Type + Prop Type"  = model3_4, "+ Superhost" = model4_1, "+ immidiate bookings" = model5_1, "+ Neighbourhoods" = model6_1, "+ Availability" = model7_1, "+ License (Final)" = model_final))

```




### Overfitting test

We now test our model for overfitting

```{r}

rmse_train <- listings_train %>% 
  mutate(predictions = predict(model_final, .)) %>% 
  summarise(sqrt(sum(predictions - log(price_4_nights))**2/n())) %>% 
  pull()
rmse_train


rmse_test <- listings_test %>% 
    mutate(predictions = predict(model_final, .)) %>% 
  summarise(sqrt(sum(predictions - log(price_4_nights))**2/n())) %>% 
  pull()
rmse_test


```

We see that the model is still closely predicting the same for the test set and training set. 








1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)



First let us define our target segment



```{r}

#Add another filter for average rating of at least 90

targets <- listings_4 %>% 
  filter(room_type == "Private room", 
         number_of_reviews >= 10, 
         review_scores_rating >= 4.5) %>% 
  mutate(log_predicted_values = predict(model_final, .),
         predicted_price = exp(log_predicted_values)) 


targets_test <- targets %>% 
  
  summarise(
    average_price=mean(predicted_price), #Mean, we choose to ignore any missing values by setting the 'na.rm = TRUE'
            
    sd_price=sd(predicted_price), #Standard Deviation
            
    count= n(), #Observations
           
    t_critical = qt(0.975,count-1), #T-Critical at 95% Confidence Interval and these observations
            
    se_price=sd_price/sqrt(count), #Standard Error 
           
    margin_of_error= t_critical*se_price, #Margin of Error
            
    price_low= average_price - margin_of_error, #Lower interval
            
    price_high= average_price + margin_of_error) #Upper Interval 


targets_test
         

skim(targets$predicted_price)



```


The point prediction is the mean equivalent of a price for 2 people for 4 nights of 379.38  
The confindence interval for the mean payment of 2 people spending 4 nights is 373-384 $. 

































```{r}
##Is the price of private room significantly lower?
listings_private<-listings_4 %>% 
  mutate(is_private_room = ifelse(property_type=="Private room in rental unit", "yes","no")) #creating categories

t.test(price ~ is_private_room, data = listings_private)
```
The t-value is way above 2 ant the p value is lower than 10^(-5). We can conclude that  private rooms seem to have a lower renting price. 
```{r}

#Using above dataset for the confidence interval calculations
formula_ci <- listings_4_room%>% 
  
  #Calculate weight's summary statistics for people exercising at least 3 times a week 
  
  # calculate mean, SD, count, SE, lower/upper 95% CI
  summarise(
    average_price=mean(price,na.rm=TRUE), #Mean, we choose to ignore any missing values by setting the 'na.rm = TRUE'
            
    sd_price=sd(price,na.rm=TRUE), #Standard Deviation
            
    count= n(), #Observations
           
    t_critical = qt(0.975,count-1), #T-Critical at 95% Confidence Interval and these observations
            
    se_price=sd_price/sqrt(count), #Standard Error 
           
    margin_of_error= t_critical*se_price, #Margin of Error
            
    price_low= average_price - margin_of_error, #Lower interval
            
    price_high= average_price + margin_of_error) #Upper Interval 

formula_ci

ggplot(formula_ci, aes(x=average_price, y=property_type, color=property_type)) +

#geom_errorbar function allows us to show the two bars with confidence intervals

geom_errorbar(aes(xmin=price_low, xmax=price_high),width = 0.1, size=0.5)+ 
  
geom_point(aes(x=average_price),size=1)+

  
theme_bw() +
  
theme(legend.position = "none",axis.title.y=element_blank())+
  
  labs(title = "CI for average price per room type",
       subtitle = "95% confidence intervals overlap",
       x = "Average Price"
       ) +
  NULL
```
The property type seems to have a significant effect on prices. The length of the intervals mainly vary due to the differences in sample size. The most common property type (Entire rental unit) has a small interval because it has the larger sample. We can estimate quite aaccuratly the average price in this category.

```{r}
favstats(price_4_nights~host_is_superhost,data=listings_4)
```
```{r}
t.test(price_4_nights ~ host_is_superhost, data = listings_4)
```

```{r}
favstats(price_4_nights~accommodates,data=listings_4)
```


```{r}

#Using above dataset for the confidence interval calculations
formula_ci <- listings_4 %>% 
  filter(accommodates<=8) %>% 
  filter(accommodates>=1) %>% 
  group_by(accommodates) %>% 
  
  #Calculate weight's summary statistics for people exercising at least 3 times a week 
  
  # calculate mean, SD, count, SE, lower/upper 95% CI
  summarise(
    average_price=mean(price,na.rm=TRUE), #Mean, we choose to ignore any missing values by setting the 'na.rm = TRUE'
            
    sd_price=sd(price,na.rm=TRUE), #Standard Deviation
            
    count= n(), #Observations
           
    t_critical = qt(0.975,count-1), #T-Critical at 95% Confidence Interval and these observations
            
    se_price=sd_price/sqrt(count), #Standard Error 
           
    margin_of_error= t_critical*se_price, #Margin of Error
            
    price_low= average_price - margin_of_error, #Lower interval
            
    price_high= average_price + margin_of_error) #Upper Interval 

formula_ci

ggplot(formula_ci, aes(x=average_price, y=accommodates, color=accommodates)) +

#geom_errorbar function allows us to show the two bars with confidence intervals

geom_errorbar(aes(xmin=price_low, xmax=price_high),width = 0.1, size=0.5)+ 
  
geom_point(aes(x=average_price),size=1)+

  
theme_bw() +
  
theme(legend.position = "none",axis.title.y=element_blank())+
  
  labs(title = "CI for average price per room type",
       subtitle = "95% confidence intervals overlap",
       x = "Average Price"
       ) +
  NULL


```

```{r}
t.test(price_4_nights ~ license, data = listings_4)
```

```{r}
#higher price in De Pijp?

listings_4_pijp<-listings_4 %>% 
  mutate(is_in_pjip = ifelse(neighbourhood_cleansed=="De Pijp - Rivierenbuurt", "yes","no"))

t.test(price_4_nights ~ is_in_pjip, data = listings_4_pijp)


```
```{r}

listings_instant<-listings2 %>% 
  select("price","instant_bookable")

listings_instant

favstats(price~instant_bookable,data=listings_instant)

t_test(price~instant_bookable,data=listings_instant)
```


## Further variables/questions to explore on our own

Our dataset has many more variables, so here are some ideas on how you can extend your analysis

1. Are the number of `bathrooms`, `bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`? Or might these be co-linear variables?
1. Do superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables?
1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?
1. For all cities, there are 3 variables that relate to neighbourhoods: `neighbourhood`, `neighbourhood_cleansed`, and `neighbourhood_group_cleansed`. There are typically more than 20 neighbourhoods in each city, and it wouldn't make sense to include them all in your model. Use your city knowledge, or ask someone with city knowledge, and see whether you can group neighbourhoods together so the majority of listings falls in fewer (5-6 max) geographical areas. You would thus need to create a new categorical variabale `neighbourhood_simplified` and determine whether location is a predictor of `price_4_nights`
1. What is the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables?


## Diagnostics, collinearity, summary tables

As you keep building your models, it makes sense to:

1. Check the residuals, using `autoplot(model_x)`
1. As you start building models with more explanatory variables, make sure you use `car::vif(model_x)`` to calculate the **Variance Inflation Factor (VIF)** for your predictors and determine whether you have colinear variables. A general guideline is that a VIF larger than 5 or 10 is large, and your model may suffer from collinearity. Remove the variable in question and run your model again without it.



1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.
1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)








# Deliverables


- By midnight on Monday 18 Oct 2021, you must upload on Canvas a short presentation (max 4-5 slides) with your findings, as some groups will be asked to present in class. You should present your Exploratory Data Analysis, as well as your best model. In addition, you must upload on Canvas your final report, written  using R Markdown to introduce, frame, and describe your story and findings. You should include the following in the memo:

1. Executive Summary: Based on your best model, indicate the factors that influence `price_4_nights`.
This should be written for an intelligent but non-technical audience. All
other sections can include technical writing.
2. Data Exploration and Feature Selection: Present key elements of the data, including tables and
graphs that help the reader understand the important variables in the dataset. Describe how the
data was cleaned and prepared, including feature selection, transformations, interactions, and
other approaches you considered.
3. Model Selection and Validation: Describe the model fitting and validation process used. State
the model you selected and why they are preferable to other choices.
4. Findings and Recommendations: Interpret the results of the selected model and discuss
additional steps that might improve the analysis
  
  

Remember to follow R Markdown etiquette rules and style; don't have the Rmd output extraneous messages or warnings, include summary tables in nice tables (use `kableExtra`), and remove any placeholder texts from past Rmd templates; in other words, (i.e. I don't want to see stuff I wrote in your final report.)
  
  
# Rubric

Your work will be assessed on a rubric which you can find here


```{r rubric, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "rubric.png"), error = FALSE)
```


# Acknowledgements

- The data for this project is from [insideairbnb.com](insideairbnb.com)




