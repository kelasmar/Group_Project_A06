---
title: "Final Group Project: AirBnB analytics"
date: "12 Oct 2021"
author: "Reading Time: About 8 minutes"
output:
  html_document:
    highlight: zenburn
    theme: flatly
    toc: yes
    toc_float: yes
    number_sections: yes
    code_folding: show
---


```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


```{r load-libraries, echo=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)
library(car)
```


# Introduction

In our final group assignment we are going to analyse data about Airbnb listings and fit a model to predict the total cost for two people staying 4 nights in an AirBnB in a city. We have chosen Amsterdam for our analysis. 

Our AirBnB data come from [insideairbnb.com](http://insideairbnb.com/get-the-data.html){target="_blank"}; it was originally scraped from airbnb.com. 


Below we load the data from Airbnb:
```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

#Load the data

listings <- vroom("http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-09-07/data/listings.csv.gz") %>% 
       clean_names()

```


Some important variables are as followed. 

- `price` = cost per night 
- `property_type`: type of accommodation (House, Apartment, etc.)
- `room_type`:

  - Entire home/apt (guests have entire place to themselves)
  - Private room (Guests have private room to sleep, all other rooms shared)
  - Shared room (Guests sleep in room shared with others)

- `number_of_reviews`: Total number of reviews for the listing
- `review_scores_rating`: Average review score (0 - 100)
- `longitude` , `latitude`: geographical coordinates to help us locate the listing
- `neighbourhood*`: three variables on a few major neighbourhoods in each city 

For further information, please refer to  [data dictionary here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896)


# Exploratory Data Analysis (EDA)

##Data overview
We use `glimpse` and `skim` to gain a general view of the data. We have 74 variables and 16,116 observations. There are 37 variables are numbers. ????? are factor variables. We also have some missing values in our data. 

```{r}
#Overview of Data
glimpse(listings)
skim(listings)

```


By plotting a cluster map that shows the number of flat listed for rent, we want to visualise the concentration of listings in the area of Amsterdam

```{r}
#Map the concentration of listing in Amsterdam
listings %>% 
  leaflet() %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1,
                   fillOpacity = 0.3, 
                   popup = ~listing_url,
                   label = ~property_type,
                   clusterOptions = markerClusterOptions()
                   )
```

From this map, we concluded that more properties are available in the central area of Amsterdam. We would like to further investigate the relationship between the price of listings and the locations of properties.

We select some variables for our analysis which we believe would be relevant to determine the impact on prices.

```{r}
#Select some variables for further exploration
listings2 <- listings %>% 
  select(c("host_since", "host_is_superhost", "neighbourhood_cleansed", "property_type", "room_type", "accommodates","price","review_scores_rating", "number_of_reviews","minimum_nights", "reviews_per_month","bedrooms","beds","availability_30","last_review","license","instant_bookable"))

# We want to choose the "bathrooms", however,this variable has no value at all

```

## Data wrangling

First lets briefly look at our new dataset

```{r}
skim(listings2)
```


We see some issues that we will try and resolve. 

First:

Some of the price data (`price`) is given as a character string, e.g., "$176.00". Since `price` is a quantitative variable, we need to make sure it is stored as numeric data `num` in the dataframe. To do so, we will first use `readr::parse_number()` which drops any non-numeric characters before or after the first number

```{r}
#Change the 'price' to numeric
listings2 <- listings2 %>% 
  mutate(price = parse_number(price))

#Use `typeof(listing2$price)` to confirm that `price` is now stored as a number.
typeof(listings2$price)

```

We then want to impute the missing value of "license" with logical judgement instead of a license number.

This will make our analysis simply focus on whether people have a license or not. 

```{r}
#Impute the missing value of “license”
listings2<-listings2 %>% 
  mutate(license = ifelse(is.na(license), "no","yes"))

```


## Property types
Next, we look at the variable `property_type`. We use the `count` function to determine how many categories there are and their frequency. 
The top 4 common property types are "Entire rental unit","Private room in rental unit","Entire residential home" and "Entire townhouse". The top 4 types make up 60.66%, 11.48%, 6.48%, and 2.66% of the total listings

```{r}
#Determine how many categories there are and their frequency
count_prop <- listings2 %>% 
  select(property_type) %>% 
  count(property_type) %>% 
  arrange(desc(n)) %>% 
  mutate(pct_type=n/sum(n)*100) #Determine the proportion of the total listings the top 4 types make up 
count_prop

```


Since the vast majority of the observations in the data are one of the top four or five property types, we would like to create a simplified version of `property_type` variable that has 5 categories: the top four categories and `Other`. Fill in the code below to create `prop_type_simplified`.


```{r}
#Simplify the "property_type" 
listings2 <- listings2 %>%
  mutate(prop_type_simplified = case_when(
    property_type %in% c("Entire rental unit",
                         "Private room in rental unit", 
                         "Entire residential home",	
                         "Entire townhouse") ~ property_type, 
    TRUE ~ "Other"))

#Check the `prop_type_simplified` was correctly made
listings2 %>%
  count(property_type, prop_type_simplified) %>%
  arrange(desc(n))    

#Removing the old property type

listings2 <- subset(listings2, select = -property_type)
  
```




## Neighbourhood
Next, we look at the variable `neighbourhood_cleansed`. We use the `count` function to determine how many categories there are and their frequency. 
The top 5 common neighbourhoods are "Da Baarshes","De Pijp","Centrum West", "Centrum Oost" and "WsterPark". The top 5 types make up 18.0%, 12.14%, 10.75%, 8.17%%, and 7.79% of the total listings

```{r}
#Determine how many categories there are and their frequency
count_prop <- listings2 %>% 
  select(neighbourhood_cleansed) %>% 
  count(neighbourhood_cleansed) %>% 
  arrange(desc(n)) %>% 
  mutate(pct_type=n/sum(n)*100) #Determine the proportion of the total listings the top 4 types make up 
count_prop

```

It seems there are too many neighbourhoods for 4 solid categories so we sort by price instead.




```{r}
neighbourhood_group <- listings2 %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarize(price_median = median(price)) %>% 
  arrange(desc(price_median))

neighbourhood_group


```

                                  

```{r}
#Simplify the "property_type" 
listings2 <- listings2 %>%
  mutate(neighbourhood_cleansed = case_when(
                                  neighbourhood_cleansed == "Centrum-Oost" ~ "Top_5",
                                  neighbourhood_cleansed == "Centrum-West" ~ "Top_5",
                                  neighbourhood_cleansed == "IJburg - Zeeburgereiland" ~ "Top_5",
                                  neighbourhood_cleansed == "Zuid" ~ "Top_5",
                                  neighbourhood_cleansed == "De Pijp - Rivierenbuurt" ~ "Top_5",
                                  neighbourhood_cleansed == "Oud-Noord" ~ "Top_6-10",
                                  neighbourhood_cleansed == "Watergraafsmeer" ~ "Top_6-10",
                                  neighbourhood_cleansed == "Oud-Oost" ~ "Top_6-10",
                                  neighbourhood_cleansed == "Westerpark" ~ "Top_6-10",
                                  neighbourhood_cleansed == "De Baarsjes - Oud-West" ~ "Top_6-10",
                                  neighbourhood_cleansed == "Noord-West" ~ "Top_11-15",
                                  neighbourhood_cleansed == "Noord-Oost" ~ "Top_11-15",
                                  neighbourhood_cleansed == "Oostelijk Havengebied - Indische Buurt" ~ "Top_11-15",
                                  neighbourhood_cleansed == "Buitenveldert - Zuidas" ~ "Top_11-15",
                                  neighbourhood_cleansed == "Bos en Lommer" ~ "Top_11-15",
                                  neighbourhood_cleansed == "Geuzenveld - Slotermeer" ~ "Remaining",
                                  neighbourhood_cleansed == "Slotervaart" ~ "Remaining",
                                  neighbourhood_cleansed == "De Aker - Nieuw Sloten" ~ "Remaining",
                                  neighbourhood_cleansed == "Osdorp" ~ "Remaining",
                                  neighbourhood_cleansed == "Gaasperdam - Driemond" ~ "Remaining",
                                  neighbourhood_cleansed == "Bijlmer-Centrum" ~ "Remaining",
                                  neighbourhood_cleansed == "Bijlmer-Oost" ~ "Remaining"))
                                  
                                
#Check the `prop_type_simplified` was correctly made
listings2 %>%
  count(neighbourhood_cleansed) %>%
  arrange(desc(n))    

```


## Minimum nights

By looking into the vairable `minimum_nights`, we found out that users who stayed for 2 nights are the most. The majority of users tend to spend less than a week, which indicates that Airbnb is most commonly used for travel purposes, i.e., as an alternative to traditional hotels. 

```{r}
#Unsolved question
#Is there any value among the common values that stands out? 
  
```
  

```{r}
#Find out the most common values for the variable `minimum_nights`
listings2 %>%
  count(minimum_nights) %>%
  arrange(desc(n))

```

We only want to include listings in our regression analysis that are intended for travel purposes, i.e. no more than 4 days.

```{r}
#Filter the Airbnb data so that it only includes observations with `minimum_nights <= 4`
listings2 <- listings2 %>% 
  filter(minimum_nights <= 4)

```


We then skim the dataset to see if further data wrangling is required.

```{r}
skim(listings2)
```

As we can see, review_scores_rating, reviews_per_month, host_is_superhost, bedrooms and beds still have missing values. We will drop unreviewed units for now and as these units will likely be less accurate in terms of price / review ratings. As for bedrooms and beds, we drop missing values.

```{r}
#Dropping values

listings2 <-  listings2 %>% 
  drop_na(bedrooms,beds,host_is_superhost,review_scores_rating,reviews_per_month)

skim(listings2)
```





## Visualisations
By visualising the relationship between price and the 4 variables that we believe will affect the price substantially, we hope to identify a noticeable correlation between price and each of those variables and use statistical modelling to further investigate their relationships and provide possible explanation.

Our four variables: 
(1) Neighbourhoods 
(2) Number of Bedrooms
(3) Ratings 
(4) License


### Overview of Price
We first take a look at the price. 

```{r}
#Overview of price
favstats(listings2$price)
```

We see that price ranges from 4 to 8,000 per night with a mean of 154 and median of 130 (i.e. some left skew)

We create the density plot of price.

```{r}

#Would be good to overlay normal distribution

#Create a density plot of prices
ggplot(listings2,aes(x=price))+
  geom_density(aes(x=price))+
  labs(title="Density plot of listing Airbnb prices",
       x="Price",
       y="Density") + 
  theme_minimal()

#Create a density plot of log of prices
ggplot(listings2,aes(x=log(price)))+
  geom_density()+
  labs(title="Density plot of listing Airbnb prices",
       x="Price",
       y="Density") + 
  theme_minimal()
```

From here forward we will use Log which is more normally distributed. 


### Location/ Neighbourhood
First, we skimmed the neighbourhood_cleansed data to analyse the distribution of price of listings depends on neighbourhood. 
From the table below,  we found out that median price will better suits the purpose of our research than the mean price because the distribution of price of each neighbourhood is greaatly skewed with extreme outliers. For example, Centrum-West neighbourhood has a mean price of USD186 while the most expensive property costs USD8000, causing a large standard deviation of USD231. Hence, standard deviation is unusually large among neighbourhood

```{r}
#Analyse the distribution of price of listings depends on neighbourhood
favstats(price~neighbourhood_cleansed,data=listings2) %>% 
  arrange(desc(n)) 

```

We then plot a density graph to see the price distribution of the most popular neighbourhood.

```{r}


#Create the dataset of the top neighbourhood and the price
listings_neigh<-listings2 %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarize(price=price)

#Plot the density graph
ggplot(listings_neigh,aes(x=log(price),fill = neighbourhood_cleansed))+
  geom_density(alpha=0.3) +    
  labs(      
      title = "Difference in price by region expensiveness",
      subtitle="Density plot for prices",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
  guides(fill=guide_legend(title="Neighbourhood regions"))+
  facet_wrap(~neighbourhood_cleansed, ncol = 1) + 
  NULL


```

The graph shows that the neighbourhoods vary in price between neighbourhoods.



```{r}
#Calculate the median price of different neighborhood
median_per_neighborhood <- listings2 %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_neighborhood,
       aes(x = reorder(neighbourhood_cleansed, median_price),
           y= median_price)) +
  geom_col(fill = "skyblue") +
  labs(
    title = "Median price per night per Neighborhood",
    x="Neighborhood",
    y="Median Price"
    ) +
  coord_flip() +
  theme_bw() +
  NULL

```

Plotting on a median price basis indicates that these prices are still indeed impacted by how close they are to center.

### Number of Bedrooms
We skimmed our data to summarise the price distribution based on number of bedrooms. 

From the table below, we noticed that listings with more than five bedrooms have less than 10 samples, therefore, we decided to only include properties with up to five bedrooms. Furthermore, we found out that median price will better suit the purpose of our research than the mean price because the distribution of price based on number of bedrooms is greatly skewed due to extreme outliers. Therefore, we believe that the median price gives better understanding of the relationship between the price and the number of bedrooms

```{r}
#Analyse the distribution of price of listings depends on number of bedrooms
favstats(price~bedrooms, data=listings2)

```
The graph shows that the listings having more bedrooms have a higher median price.

```{r}
#Filter the bedrooms under 5 for further discussion

listings2 <- listings2 %>% 
  filter(bedrooms<=5)

median_per_bedroom <- listings2 %>% 
  group_by(bedrooms) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_bedroom,
       aes(x = reorder(bedrooms,median_price),
           y= median_price)) +
  geom_col(fill = "orchid3") +
  labs(
    title = "Median price per night per bedrooms",
    x="Number of Bedrooms",
    y="Median Price"
    ) +
  theme_bw() +
  NULL
```

### Ratings 
We skimmed our data to summarise the price distribution based on the rating score.

```{r}
#Analyse the distribution of price of listings depends on the rating score
favstats(price~review_scores_rating,data=listings2)
```

By drawing a regression line between the median price and the ratings, we concluded that they share a positive correlation, which means higher ratings have higher median price, and vice versa.

```{r}
##Create the data of price and score rating
median_per_rating <- listings2 %>% 
  group_by(review_scores_rating) %>% 
  summarise(median_price = median(price)) %>% 
  na.omit()


ggplot(median_per_rating,
       aes(x = review_scores_rating,
           y= median_price)) +
  geom_point(color="red") +
  labs(title = "Median price per night vs. Ratings",
    x="Ratings",
    y="Median Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  NULL


```


We further find out that superhost has higher rating than non superhost by coloring the below above graph by host type.

```{r}
#Create the data of price, score rating, and superhost
median_per_rating1 <- listings2 %>% 
  group_by(review_scores_rating) %>% 
  summarise(median_price = median(price),
            host_is_superhost=host_is_superhost) %>% 
  na.omit()


ggplot(median_per_rating1,
       aes(x = review_scores_rating,
           y= median_price)) +
  geom_point(aes(colour = host_is_superhost)) +
  labs(title = "Median price per night vs. Ratings",
    x="Ratings",
    y="Median Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  guides(fill=guide_legend(title="Host is Superhost"))+
  
  NULL

```


Similarly we can graph a relationship between number of reviews and price

```{r}
ggplot(listings2, 
       aes(x = number_of_reviews,
           y= log(price))) +
  geom_point(color="red") +
  labs(title = "Price per night vs. number of Reviews",
    x="Number of Reviews",
    y="Log Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  NULL
```

WE see that as the number of reviews increase the price falls, likely because these are less premium properties. 

### License 
We want to find out the relationship between license and price of linceses. By graphing a boxplot, we see that properties with license have higher Q1, median and Q3 value than properties without license. Hence, we conclude that properties with licence are more expensive than the others.

```{r}
listing2_low_price <- listings2 

ggplot(listing2_low_price,aes(x=license,y=log(price)))+
  geom_boxplot(fill="wheat2")+
  labs(title = "Price per night vs. License",
    x="License",
    y=" Price"
    )+
  theme_bw()

```
We see that there is a higher spread on prices of properties without licenses and a slightly lower average. 


### Room type

```{r}
#Calculate the median price of different room types
median_per_room <- listings2 %>% 
  group_by(room_type) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_room,
       aes(x = reorder(room_type, median_price),
           y= median_price)) +
  geom_col(fill = "skyblue") +
  labs(
    title = "Median price by room_type",
    x="Room Type",
    y="Median Price"
    ) +
  coord_flip() +
  theme_bw() +
  NULL
```
We see that entire homes and hotel rooms are especially expensive. We can also plot the density of this




```{r}
#Create the dataset of the top Room type and the price
listings_room<-listings2 %>% 
  group_by(room_type) %>% 
  summarize(price=price)

#Plot the density graph
ggplot(listings_room,aes(x=log(price),fill = room_type))+
  geom_density(alpha=0.3) +    
  labs(      
      title = "Price distribution in room types",
      subtitle="Density plot for prices in different room types",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
  guides(fill=guide_legend(title="Room types"))+
  facet_wrap(~room_type, ncol = 1) + 
  NULL


```
Interestingly although entire homes or apartments are the most expensive in terms of median, we see that some hotels are also extremely expensive.



### Property Type

```{r}
#Calculate the median price of different room types
median_per_prop <- listings2 %>% 
  group_by(prop_type_simplified) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_prop,
       aes(x = reorder(prop_type_simplified, median_price),
           y= median_price)) +
  geom_col(fill = "skyblue") +
  labs(
    title = "Median price by property type",
    x="Room Type",
    y="Median Price"
    ) +
  coord_flip() +
  theme_bw() +
  NULL
```

### Avaialability next 30 days

```{r}
listings_availability<-listings2 %>% 
  group_by(availability_30) %>% 
  summarize(price=median(price))


ggplot(listings_availability, 
       aes(x = availability_30,
           y= log(price))) +
  geom_point(color="red") +
  labs(title = "Median Price Per Night versus Availability",
    x="Availability next 30 days",
    y="Log Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  NULL
```
Interestingly the more availability the higher the price indicating that more premium rooms are booked less often or are less often fully booked. 


### Instant Bookable

Last but nost least we will look at whether or not units are instantly bookable

```{r}

ggplot(listings2,aes(x=instant_bookable,y=log(price)))+
  geom_boxplot(fill="wheat2")+
  labs(title = "Distribution of whether or not units are instantly bookable",
    x="Instantly Bookable",
    y="Log Price"
    )+
  theme_bw()

```
There seems to be little to no difference between whether or not the units are bookable 


### Paired relationship overview
We plotted a GG pairs plot to get a comprehensive overview of the relationship between the price of listings and the selected variables. 

```{r}
##Problem: 1. what variables to choose? 2.Do we need further explanation for this part?

#DME Comment - i think we should do a bunch to all
```


```{r}
#Relatonship between the price and variables, starting with numerical variables
listings2 %>% 
  select(price,accommodates, review_scores_rating, number_of_reviews, minimum_nights, reviews_per_month, bedrooms, beds, availability_30) %>% 
  ggpairs(aes(alpha=0.2))+
  theme_minimal(base_size=8)

```
From the above we see that for price the most correlated variables is the number of accomodates or bedrooms (although these are  correlated with 0.73 and will likely not both be included). However, from here it seems that oerhaps it is better to focus on accommodates rather than bedrooms. 

Unfortunately, GGPairs does not work well with categorical variables and we will use that data we extracted above as an indicator for whether or not these variables will be useful going forward
`

# Regression Analysis
For the target variable $Y$, we will use the cost for two people to stay at an Airbnb location for four (4) nights. 
We first create a new variable called `price_4_nights` that uses `price`, and `accomodates` to calculate the total cost for two people to stay at the Airbnb property for 4 nights. This is the variable $Y$ we want to explain.


We assume that this leaves us with Airbnbs accommodating 2 or more people. I.e. we filter out Airbnb's which accomodate 1 person. 

Also, we assume that no other people would go to the airbnb lowering the cost per person (i.e. 2 people could rent a 10 people Airbnb but would be the only two to pay)

```{r}
##Fist, we have to filter the data to represent 2 people staying for 4 nights.
listings_4 <- listings2 %>% 
  filter(accommodates>=2) %>% 
  mutate(price_4_nights =price*4)

```

We take logarithm of ’price_4_nights‘ and create the density plot, because it looks more like the normal distribution

```{r}
#Unvertain answer: Use histograms or density plots to examine the distributions of `price_4_nights` and `log(price_4_nights)`. Which variable should you use for the regression model? Why?
```


```{r}
# Plot density of price using price_4_nights
ggplot(listings_4,aes(x=price_4_nights))+
  geom_density() +    
  labs(      
      title = "Density plot for prices for 4 nights",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
    NULL

# Plot density of price using log(price_4_nights)
ggplot(listings_4,aes(x=log(price_4_nights)))+
  geom_density() +    
  labs(      
      title = "Density plot for prices for 4 nights",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
    NULL
```

We see that taking the log of prices brings us much closer to a normal distribution why we use log prices going forward. 


## Model1: property type, number of reviews and the rating scores
We first fit a regression model with the following explanatory variables: `prop_type_simplified`, `number_of_reviews`, and `review_scores_rating`. 


First, let us split the data into a training and testing set. The training will be used for the models


```{r}
set.seed(123456)

train_test_split <- initial_split(listings_4, prop = 0.75)
listings_train <- training(train_test_split)
listings_test <- testing(train_test_split)
```


```{r}

#Create the model1
model1 <- lm(log(price_4_nights) ~ prop_type_simplified +number_of_reviews +review_scores_rating ,data=listings_train)
summary(model1)

```


We come to an adjusted R squared of 0.169 which is a good start. We see that all variables have significant t-values indicating they are significantly different from 0. 

Also, We see that some room types (such as entire residential home or townhouse willa dd to the price and other and private room will lower the price)

More specifically these values changes as units changed compared to the unit left out ()

- Entire residential home increases log of price 0.2 
- Entire Townhouse increases log of price 0.28
- Other  decreases log of price 0.007
- Private room decreases log of price 0.53

These numbers are compared to if the unit is entire rental Unit which is the variable excluded (Categorical Variables exclude one variable)



These variables are compared to whether or not the unit is 


For review scores rating we see that as rating goes up 1 unit log of price goes up 0.019. 

However, as number of reviews goes up price goes down. For every 100 additional reviews price falls roughly 0.05 (Likely because those properties are less premium).


## Room Type
Now lets add the room type

```{r}
#Create the model1
model2 <- lm(log(price_4_nights) ~ prop_type_simplified +number_of_reviews +review_scores_rating + room_type ,data=listings_train)
summary(model2)
```
Our model now explains slightly more butsome variables are no longer significant.

Specificallywe see that hotel rooms, private rooms and shared rooms all lower the price compared to entire home/apt. 

Lets now test for VIF given our model has some p-value issues:

```{r}
car::vif(model2)
```
Let's keep the variables in 



## Model 3: Bedrooms, beds and accomodates
We want to further determine whether the number of`bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`.

WE surprisingly see that VIF is not too high between beds, bedrooms, and accomodates so we keep them in for now. We will now include beds, because it is insignificant. 

We do see that these factors explain quite well the price changes and has an Rsquare of 0.2818. Lets add it to our model

```{r}


model3_1 <- lm(log(price_4_nights) ~ prop_type_simplified+number_of_reviews+review_scores_rating + beds +  room_type+bedrooms + accommodates, data = listings_4)

```

```{r}
summary(model3_2)
```
Once again we get a higher R Square but some of these variables are no longer significant. 

Let's check VIF

```{r}
vif(model3_2)
```
WE now see quite a high variance inflation factor for Prop_type_simplified, and Room Type. This makes sense as the room type (i.e. hotel room) is related to property type (i.e. a hotel)

Let's try and run and see each model without one another. 

```{r}
###
model3_3 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates, data = listings_4)
model3_4 <- lm(log(price_4_nights) ~ prop_type_simplified+number_of_reviews+review_scores_rating + bedrooms + accommodates, data = listings_4)

vif(model3_3)
vif(model3_4)


```

We immidieatly lower our variance inflation factor. 

Now let's try and decide which model is stronger going forward. 

```{r}
summary(model3_3)
summary(model3_4)
```
We see that model 3_3 (room type) provides better explanatory power than 3_4 (property type), and will utilize that going forward. 


### Model4: Superhosts
We want to explore whether the superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables. 

First let us look at superhosts on a standalone basis 

```{r}
model4_1 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost, data = listings_4)
summary(model4_1)

```

The variable is significant however, it only has very little explanatory power. Let's try and compute the VIF once again to check out model


> DME comment, i am uncertain when we should take out non-significant variables and when to run the test (splitting the data)



```{r}
vif(model4_1)
```
We see that VIF is below 5 for all variables meaning the variables do not have too high correlation

### Model 5, Immidiate bookings

1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?

```{r}
model5_1 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost + instant_bookable, data = listings_4)
summary(model5_1)

```

Here we see instant bookable is a significant predictor which will can be used in our model. 

We once again control VIF
```{r}
vif(model5_1)

```
Still these factors are not correlated enough for us to be worried. 


### Neighboughoods 

For this section we have not chosen the neighbourhood_overview variables as it had a lot of NAs. 

```{r}
model6_1 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost + instant_bookable + neighbourhood_cleansed, data = listings_4)
summary(model6_1)
```

We see that neighbourgood categorization is a really impactful driver on our prices. 

Testing VIF
```{r}
vif(model6_1)
```
Still VIF looks fine.


### Availability

Next lets look at availability in the coming 30 days

```{r}
model7_1 <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost + instant_bookable + neighbourhood_cleansed + availability_30, data = listings_4)
summary(model7_1)
```

Once again, this variable is a significant explanatory variable. Let's test for VIF once again:

```{r}
vif(model7_1)
```

All VIFS are low and therefore we make no changes.

### License

```{r}
model_final <- lm(log(price_4_nights) ~ number_of_reviews+review_scores_rating + room_type+bedrooms + accommodates + host_is_superhost + instant_bookable + neighbourhood_cleansed + availability_30 + license, data = listings_4)
summary(model_final)
```


License is indeed a significant predictor of price

```{r}
vif(model_final)
```




## Diagnostics, collinearity, summary tables

Final VIF

```{r}
vif(model_final)
```


Variance inflation factor is below 5 for all variables. 

```{r}
autoplot(model_final)
```
For our model we see that resudual errors are evenly distributed and do not change as the variable fitted values change. This is a good sign for our model.

Futhermore we see from the theoretical quantiles that our model is approximately evenly distributed but not 100% evenly distributed. 

As you keep building your models, it makes sense to:



1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.




Given the above, it seems both beds and license can be removed without any material effect. 

Final Table


```{r}
huxreg(list("Prop Type, Reviews, Rating" = model1, "+ Room Type" = model2, "+ Beds + Bedrooms + Accom." = model3_2, "- Prop Type" = model3_3, " - Room Type + Prop Type"  = model3_4, "+ Superhost" = model4_1, "+ immidiate bookings" = model5_1, "+ Neighbourhoods" = model6_1, "+ Availability" = model7_1, "+ License (Final)" = model_final))

```




### Overfitting test

We now test our model for overfitting

```{r}

rmse_train <- listings_train %>% 
  mutate(predictions = predict(model_final, .)) %>% 
  summarise(sqrt(sum(predictions - log(price_4_nights))**2/n())) %>% 
  pull()
rmse_train


rmse_test <- listings_test %>% 
    mutate(predictions = predict(model_final, .)) %>% 
  summarise(sqrt(sum(predictions - log(price_4_nights))**2/n())) %>% 
  pull()
rmse_test


```

We see that the model is still closely predicting the same for the test set and training set. 








1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)



First let us define our target segment



```{r}

#Add another filter for average rating of at least 90

targets <- listings_4 %>% 
  filter(room_type == "Private room", 
         number_of_reviews >= 10, 
         review_scores_rating >= 4.5) %>% 
  mutate(log_predicted_values = predict(model_final, .),
         predicted_price = exp(log_predicted_values)) 


targets_test <- targets %>% 
  
  summarise(
    average_price=mean(predicted_price), #Mean, we choose to ignore any missing values by setting the 'na.rm = TRUE'
            
    sd_price=sd(predicted_price), #Standard Deviation
            
    count= n(), #Observations
           
    t_critical = qt(0.975,count-1), #T-Critical at 95% Confidence Interval and these observations
            
    se_price=sd_price/sqrt(count), #Standard Error 
           
    margin_of_error= t_critical*se_price, #Margin of Error
            
    price_low= average_price - margin_of_error, #Lower interval
            
    price_high= average_price + margin_of_error) #Upper Interval 


targets_test
         

skim(targets$predicted_price)



```


The point prediction is the mean equivalent of a price for 2 people for 4 nights of 379.38  
The confindence interval for the mean payment of 2 people spending 4 nights is 373-384 $. 

































```{r}
##Is the price of private room significantly lower?
listings_private<-listings_4 %>% 
  mutate(is_private_room = ifelse(property_type=="Private room in rental unit", "yes","no")) #creating categories

t.test(price ~ is_private_room, data = listings_private)
```
The t-value is way above 2 ant the p value is lower than 10^(-5). We can conclude that  private rooms seem to have a lower renting price. 
```{r}

#Using above dataset for the confidence interval calculations
formula_ci <- listings_4_room%>% 
  
  #Calculate weight's summary statistics for people exercising at least 3 times a week 
  
  # calculate mean, SD, count, SE, lower/upper 95% CI
  summarise(
    average_price=mean(price,na.rm=TRUE), #Mean, we choose to ignore any missing values by setting the 'na.rm = TRUE'
            
    sd_price=sd(price,na.rm=TRUE), #Standard Deviation
            
    count= n(), #Observations
           
    t_critical = qt(0.975,count-1), #T-Critical at 95% Confidence Interval and these observations
            
    se_price=sd_price/sqrt(count), #Standard Error 
           
    margin_of_error= t_critical*se_price, #Margin of Error
            
    price_low= average_price - margin_of_error, #Lower interval
            
    price_high= average_price + margin_of_error) #Upper Interval 

formula_ci

ggplot(formula_ci, aes(x=average_price, y=property_type, color=property_type)) +

#geom_errorbar function allows us to show the two bars with confidence intervals

geom_errorbar(aes(xmin=price_low, xmax=price_high),width = 0.1, size=0.5)+ 
  
geom_point(aes(x=average_price),size=1)+

  
theme_bw() +
  
theme(legend.position = "none",axis.title.y=element_blank())+
  
  labs(title = "CI for average price per room type",
       subtitle = "95% confidence intervals overlap",
       x = "Average Price"
       ) +
  NULL
```
The property type seems to have a significant effect on prices. The length of the intervals mainly vary due to the differences in sample size. The most common property type (Entire rental unit) has a small interval because it has the larger sample. We can estimate quite aaccuratly the average price in this category.

```{r}
favstats(price_4_nights~host_is_superhost,data=listings_4)
```
```{r}
t.test(price_4_nights ~ host_is_superhost, data = listings_4)
```

```{r}
favstats(price_4_nights~accommodates,data=listings_4)
```


```{r}

#Using above dataset for the confidence interval calculations
formula_ci <- listings_4 %>% 
  filter(accommodates<=8) %>% 
  filter(accommodates>=1) %>% 
  group_by(accommodates) %>% 
  
  #Calculate weight's summary statistics for people exercising at least 3 times a week 
  
  # calculate mean, SD, count, SE, lower/upper 95% CI
  summarise(
    average_price=mean(price,na.rm=TRUE), #Mean, we choose to ignore any missing values by setting the 'na.rm = TRUE'
            
    sd_price=sd(price,na.rm=TRUE), #Standard Deviation
            
    count= n(), #Observations
           
    t_critical = qt(0.975,count-1), #T-Critical at 95% Confidence Interval and these observations
            
    se_price=sd_price/sqrt(count), #Standard Error 
           
    margin_of_error= t_critical*se_price, #Margin of Error
            
    price_low= average_price - margin_of_error, #Lower interval
            
    price_high= average_price + margin_of_error) #Upper Interval 

formula_ci

ggplot(formula_ci, aes(x=average_price, y=accommodates, color=accommodates)) +

#geom_errorbar function allows us to show the two bars with confidence intervals

geom_errorbar(aes(xmin=price_low, xmax=price_high),width = 0.1, size=0.5)+ 
  
geom_point(aes(x=average_price),size=1)+

  
theme_bw() +
  
theme(legend.position = "none",axis.title.y=element_blank())+
  
  labs(title = "CI for average price per room type",
       subtitle = "95% confidence intervals overlap",
       x = "Average Price"
       ) +
  NULL


```

```{r}
t.test(price_4_nights ~ license, data = listings_4)
```

```{r}
#higher price in De Pijp?

listings_4_pijp<-listings_4 %>% 
  mutate(is_in_pjip = ifelse(neighbourhood_cleansed=="De Pijp - Rivierenbuurt", "yes","no"))

t.test(price_4_nights ~ is_in_pjip, data = listings_4_pijp)


```
```{r}

listings_instant<-listings2 %>% 
  select("price","instant_bookable")

listings_instant

favstats(price~instant_bookable,data=listings_instant)

t_test(price~instant_bookable,data=listings_instant)
```


## Further variables/questions to explore on our own

Our dataset has many more variables, so here are some ideas on how you can extend your analysis

1. Are the number of `bathrooms`, `bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`? Or might these be co-linear variables?
1. Do superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables?
1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?
1. For all cities, there are 3 variables that relate to neighbourhoods: `neighbourhood`, `neighbourhood_cleansed`, and `neighbourhood_group_cleansed`. There are typically more than 20 neighbourhoods in each city, and it wouldn't make sense to include them all in your model. Use your city knowledge, or ask someone with city knowledge, and see whether you can group neighbourhoods together so the majority of listings falls in fewer (5-6 max) geographical areas. You would thus need to create a new categorical variabale `neighbourhood_simplified` and determine whether location is a predictor of `price_4_nights`
1. What is the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables?


## Diagnostics, collinearity, summary tables

As you keep building your models, it makes sense to:

1. Check the residuals, using `autoplot(model_x)`
1. As you start building models with more explanatory variables, make sure you use `car::vif(model_x)`` to calculate the **Variance Inflation Factor (VIF)** for your predictors and determine whether you have colinear variables. A general guideline is that a VIF larger than 5 or 10 is large, and your model may suffer from collinearity. Remove the variable in question and run your model again without it.



1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.
1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)








# Deliverables


- By midnight on Monday 18 Oct 2021, you must upload on Canvas a short presentation (max 4-5 slides) with your findings, as some groups will be asked to present in class. You should present your Exploratory Data Analysis, as well as your best model. In addition, you must upload on Canvas your final report, written  using R Markdown to introduce, frame, and describe your story and findings. You should include the following in the memo:

1. Executive Summary: Based on your best model, indicate the factors that influence `price_4_nights`.
This should be written for an intelligent but non-technical audience. All
other sections can include technical writing.
2. Data Exploration and Feature Selection: Present key elements of the data, including tables and
graphs that help the reader understand the important variables in the dataset. Describe how the
data was cleaned and prepared, including feature selection, transformations, interactions, and
other approaches you considered.
3. Model Selection and Validation: Describe the model fitting and validation process used. State
the model you selected and why they are preferable to other choices.
4. Findings and Recommendations: Interpret the results of the selected model and discuss
additional steps that might improve the analysis
  
  

Remember to follow R Markdown etiquette rules and style; don't have the Rmd output extraneous messages or warnings, include summary tables in nice tables (use `kableExtra`), and remove any placeholder texts from past Rmd templates; in other words, (i.e. I don't want to see stuff I wrote in your final report.)
  
  
# Rubric

Your work will be assessed on a rubric which you can find here


```{r rubric, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "rubric.png"), error = FALSE)
```


# Acknowledgements

- The data for this project is from [insideairbnb.com](insideairbnb.com)




