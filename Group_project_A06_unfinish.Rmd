---
title: "Final Group Project: AirBnB analytics"
date: "12 Oct 2021"
author: "Reading Time: About 8 minutes"
output:
  html_document:
    highlight: zenburn
    theme: flatly
    toc: yes
    toc_float: yes
    number_sections: yes
    code_folding: show
---


```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


```{r load-libraries, echo=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)
```


# Introduction

In our final group assignment we are going to analyse data about Airbnb listings and fit a model to predict the total cost for two people staying 4 nights in an AirBnB in a city. 

Our AirBnB data come from [insideairbnb.com](http://insideairbnb.com/get-the-data.html){target="_blank"}; it was originally scraped from airbnb.com. 


```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

#Load the data

listings <- vroom("http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-09-07/data/listings.csv.gz") %>% 
       clean_names()

```


Some important variables are as followed. 

- `price` = cost per night 
- `property_type`: type of accommodation (House, Apartment, etc.)
- `room_type`:

  - Entire home/apt (guests have entire place to themselves)
  - Private room (Guests have private room to sleep, all other rooms shared)
  - Shared room (Guests sleep in room shared with others)

- `number_of_reviews`: Total number of reviews for the listing
- `review_scores_rating`: Average review score (0 - 100)
- `longitude` , `latitude`: geographical coordinates to help us locate the listing
- `neighbourhood*`: three variables on a few major neighbourhoods in each city 

For further information, please refer to  [data dictionary here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896)


# Exploratory Data Analysis (EDA)

##Data overview
We use `glimpse` and `skim` to gain a general view of the data. We have 74 variables and 16,116 observations. There are 37 variables are numbers. ????? are factor variables. We also have some missing values in our data. 

```{r}
#Overview of Data
glimpse(listings)
skim(listings)

```


By plotting a cluster map that shows the number of flat listed for rent, we want to visualise the concentration of listings in the area of Amsterdam

```{r}
#Map the concentration of listing in Amsterdam
listings %>% 
  leaflet() %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1,
                   fillOpacity = 0.3, 
                   popup = ~listing_url,
                   label = ~property_type,
                   clusterOptions = markerClusterOptions()
                   )
```

From this map, we concluded that more properties are available in the central area of Amsterdam. We would like to further investigate the relationship between the price of listings and the locations of properties.

We select some variables for our analysis.

```{r}
#Select some variables for further exploration
listings2 <- listings %>% 
  select(c("host_since", "host_is_superhost", "neighbourhood_cleansed", "property_type", "room_type", "accommodates","price","review_scores_rating", "number_of_reviews","minimum_nights", "reviews_per_month","bedrooms","beds","availability_30","last_review","license","instant_bookable"))

# We want to choose the "bathrooms", however,this variable has no value at all

```

## Data wrangling

Some of the price data (`price`) is given as a character string, e.g., "$176.00". Since `price` is a quantitative variable, we need to make sure it is stored as numeric data `num` in the dataframe. To do so, we will first use `readr::parse_number()` which drops any non-numeric characters before or after the first number

```{r}
#Change the 'price' to numeric
listings2 <- listings2 %>% 
  mutate(price = parse_number(price))

#Use `typeof(listing2$price)` to confirm that `price` is now stored as a number.
typeof(listings2$price)

```

We then want to impute the missing value of "license" with logical judgement. 

```{r}
#Impute the missing value of “license”
listings2<-listings2 %>% 
  mutate(license = ifelse(is.na(license), "no","yes"))

```


## Property types
Next, we look at the variable `property_type`. We use the `count` function to determine how many categories there are and their frequency. 
The top 4 common property types are "Entire rental unit","Private room in rental unit","Entire residential home" and "Entire townhouse". The top 4 types make up 60.66%, 11.48%, 6.48%, and 2.66% of the total listings

```{r}
#Determine how many categories there are and their frequency
count_prop <- listings2 %>% 
  select(property_type) %>% 
  count(property_type) %>% 
  arrange(desc(n)) %>% 
  mutate(pct_type=n/sum(n)*100) #Determine the proportion of the total listings the top 4 types make up 
count_prop

```


Since the vast majority of the observations in the data are one of the top four or five property types, we would like to create a simplified version of `property_type` variable that has 5 categories: the top four categories and `Other`. Fill in the code below to create `prop_type_simplified`.


```{r}
#Simplify the "property_type" 
listings2 <- listings2 %>%
  mutate(prop_type_simplified = case_when(
    property_type %in% c("Entire rental unit",
                         "Private room in rental unit", 
                         "Entire residential home",	
                         "Entire townhouse") ~ property_type, 
    TRUE ~ "Other"))

#Check the `prop_type_simplified` was correctly made
listings2 %>%
  count(property_type, prop_type_simplified) %>%
  arrange(desc(n))    
  
```

## Minimum nights

By looking into the vairable `minimum_nights`, we found out that users who stayed for 2 nights are the most. The majority of users tend to spend less than a week, which indicates that Airbnb is most commonly used for travel purposes, i.e., as an alternative to traditional hotels. 

```{r}
#Unsolved question
#Is there any value among the common values that stands out? 
  
```
  

```{r}
#Find out the most common values for the variable `minimum_nights`
listings2 %>%
  count(minimum_nights) %>%
  arrange(desc(n))

```

We only want to include listings in our regression analysis that are intended for travel purposes, i.e. no more than 4 days.

```{r}
#Filter the Airbnb data so that it only includes observations with `minimum_nights <= 4`
listings2 <- listings2 %>% 
  filter(minimum_nights <= 4)

```


We then skim the dataset to see if further data wrangling is required.

```{r}
skim(listings2)
```
As we can see, review_scores_rating, reviews_per_month, host_is_superhost, bedrooms and beds still have missing values. We will replace missing values of review_scores_rating and reviews_per_month with average review_scores_rating and reviews_per_month.As for bedrooms and beds, we drop missing values.

```{r}
#Replace the missing value of reviews_per_month and reviews_per_month
avg_rating= mean(listings2$review_scores_rating,na.rm=TRUE)
avg_reviews=mean(listings2$reviews_per_month,na.rm=TRUE)

listings2<-listings2 %>% 
  mutate(review_scores_rating=ifelse(is.na(review_scores_rating),avg_rating,review_scores_rating),
        reviews_per_month=ifelse(is.na(reviews_per_month),avg_reviews,reviews_per_month) )

# Remove missing values of host_is_superhost, bedrooms and beds
listings2<-listings2 %>%
  drop_na(bedrooms,beds,host_is_superhost)

skim(listings2)
```



## Visualisations
By visualising the relationship between price and the 4 variables that we believe will affect the price substantially, we hope to identify a noticeable correlation between price and each of those variables and use statistical modelling to further investigate their relationships and provide possible explanation.

Our four variables: 
(1) Neighbourhoods 
(2) Number of Bedrooms
(3) Ratings 
(4) License


### Overview of Price
We first take a look at the price. 

```{r}
#Overview of price
favstats(listings2$price)
```

We create the density plot of price.

```{r}
#Create a density plot
ggplot(listings2,aes(x=price))+
  geom_density(aes(x=price))+
  scale_x_log10()+ # We use the log(price) 
  labs(title="Density plot of listing Airbnb prices",
       x="Price",
       y="Density")+
  theme_minimal()
```

### Location/ Neighbourhood
First, we skimmed the neighbourhood_cleansed data to analyse the distribution of price of listings depends on neighbourhood. 
From the table below,  we found out that median price will better suits the purpose of our research than the mean price because the distribution of price of each neighbourhood is greaatly skewed with extreme outliers. For example, Centrum-West neighbourhood has a mean price of USD186 while the most expensive property costs USD8000, causing a large standard deviation of USD231. Hence, standard deviation is unusually large among neighbourhood

```{r}
#Analyse the distribution of price of listings depends on neighbourhood
favstats(price~neighbourhood_cleansed,data=listings2) %>% 
  arrange(desc(n)) 

```

We then plot a density graph to see the price distribution of the most popular neighbourhood.

```{r}
#Filter the most popular neighbourhood
main_neighbourhood <-favstats(price~neighbourhood_cleansed,data=listings2) %>% 
  filter(n>=1000) %>% 
  arrange(desc(n))

top_neighbourhood=main_neighbourhood$neighbourhood_cleansed

#Create the dataset of the top neighbourhood and the price
listings_neigh<-listings2 %>% 
  group_by(neighbourhood_cleansed) %>% 
  filter(neighbourhood_cleansed==top_neighbourhood) %>% 
  summarize(price=price)

#Plot the density graph
ggplot(listings_neigh,aes(x=log(price),fill = neighbourhood_cleansed))+
  geom_density(alpha=0.3) +    
  labs(      
      title = "Price distribution in the most popular regions",
      subtitle="Density plot for prices in the most popular regions",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
  guides(fill=guide_legend(title="Neighbourhood regions"))+
  NULL


```

The graph below shows that as we get closer to center, the more expensive the Airbnb becomes. This confirms that location has a substantial impact on the price of listings.

```{r}
#Problem: I think this part has some problem. How do we know that these neighbourhood are close to the center? By its name? 
```


```{r}
#Calculate the median price of different neighborhood
median_per_neighborhood <- listings2 %>% 
  group_by(neighbourhood_cleansed) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_neighborhood,
       aes(x = reorder(neighbourhood_cleansed, median_price),
           y= median_price)) +
  geom_col(fill = "skyblue") +
  labs(
    title = "Median price per night per Neighborhood",
    x="Neighborhood",
    y="Median Price"
    ) +
  coord_flip() +
  theme_bw() +
  NULL

```

### Number of Bedrooms
We skimmed our data to summarise the price distribution based on number of bedrooms. 

From the table below, we noticed that listings with more than five bedrooms have less than 10 samples, therefore, we decided to only include properties with up to five bedrooms. Furthermore, we found out that median price will better suit the purpose of our research than the mean price because the distribution of price based on number of bedrooms is greatly skewed due to extreme outliers. Therefore, we believe that the median price gives better understanding of the relationship between the price and the number of bedrooms

```{r}
#Analyse the distribution of price of listings depends on number of bedrooms
favstats(price~bedrooms, data=listings2)

```
The graph shows that the listings having more bedrooms have a higher median price.

```{r}
#Filter the bedrooms under 5 for further discussion
median_per_bedroom <- listings2 %>% 
  group_by(bedrooms) %>% 
  filter(bedrooms<=5) %>% 
  summarise(median_price = median(price))

#Plot the graph
ggplot(median_per_bedroom,
       aes(x = reorder(bedrooms,median_price),
           y= median_price)) +
  geom_col(fill = "orchid3") +
  labs(
    title = "Median price per night per bedrooms",
    x="Number of Bedrooms",
    y="Median Price"
    ) +
  theme_bw() +
  NULL
```

### Ratings 
We skimmed our data to summarise the price distribution based on the rating score.

```{r}
#Analyse the distribution of price of listings depends on the rating score
favstats(price~review_scores_rating,data=listings2)
```

By drawing a regression line between the median price and the ratings, we concluded that they share a positive correlation, which means higher ratings have higher median price, and vice versa.

```{r}
##Create the data of price and score rating
median_per_rating <- listings2 %>% 
  group_by(review_scores_rating) %>% 
  summarise(median_price = median(price)) %>% 
  na.omit()


ggplot(median_per_rating,
       aes(x = review_scores_rating,
           y= median_price)) +
  geom_point(color="red") +
  labs(title = "Median price per night vs. Ratings",
    x="Ratings",
    y="Median Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  NULL
```


We further find out that superhost has higher rating than non superhost. 

```{r}
#Create the data of price, score rating, and superhost
median_per_rating1 <- listings2 %>% 
  group_by(review_scores_rating) %>% 
  summarise(median_price = median(price),
            host_is_superhost=host_is_superhost) %>% 
  na.omit()


ggplot(median_per_rating1,
       aes(x = review_scores_rating,
           y= median_price)) +
  geom_point(aes(colour = host_is_superhost)) +
  labs(title = "Median price per night vs. Ratings",
    x="Ratings",
    y="Median Price"
    ) +
  geom_smooth(method=lm,colour="black",alpha=0)+
  theme_bw() +
  guides(fill=guide_legend(title="Host is Superhost"))+
  
  NULL

```

### License 
We want to find out the relationship between license and price of listins. By graphing a boxplot, we see that properties with license have higher Q1, median and Q3 value than properties without license. Hence, we conclude that properties with licence are more expensive than the others.

```{r}
#???Problem: Why do we filter the price over 800
listing2_low_price <- listings2 %>% 
  filter(price<=800)

ggplot(listing2_low_price,aes(x=license,y=price))+
  geom_boxplot(fill="wheat2")+
  labs(title = "Price per night vs. License",
    x="License",
    y=" Price"
    )+
  theme_bw()

##not relevant
```
### Room type

```{r}
###Unfinished
```



### Paired relationship overview
We plotted a GG pairs plot to get a comprehensive overview of the relationship between the price of listings and the selected variables. 

```{r}
##Problem: 1. what variables to choose? 2.Do we need further explanation for this part?
```


```{r}
#Relatonship between the price and variables
listings2 %>% 
  select(price,host_is_superhost, review_scores_rating, accommodates,bedrooms,prop_type_simplified) %>% 
  ggpairs()+
  theme_minimal(base_size=8)

```


# Regression Analysis
For the target variable $Y$, we will use the cost for two people to stay at an Airbnb location for four (4) nights. 
We first create a new variable called `price_4_nights` that uses `price`, and `accomodates` to calculate the total cost for two people to stay at the Airbnb property for 4 nights. This is the variable $Y$ we want to explain.

```{r}
##Fist, we have to filter the data to represent 2 people staying for 4 nights.
listings_4 <- listings2 %>% 
  filter(accommodates>=2) %>% 
  mutate(price_4_nights =price*4)

```

We take logarithm of ’price_4_nights‘ and create the density plot, because it looks more like the normal distribution

```{r}
#Unvertain answer: Use histograms or density plots to examine the distributions of `price_4_nights` and `log(price_4_nights)`. Which variable should you use for the regression model? Why?
```


```{r}
# Plot density of price using log(price_4_nights)
ggplot(listings_4,aes(x=price))+
  geom_density() +    
  scale_x_log10()+
  labs(      
      title = "Density plot for prices for 4 nights",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
    NULL
```

## Model1: property type, number of reviews and the rating scores
We first fit a regression model with the following explanatory variables: `prop_type_simplified`, `number_of_reviews`, and `review_scores_rating`. 

```{r}
#Mutate a new variable of log(number_of_reviews)
listings_4 <- listings_4%>% 
  mutate(log_number_of_reviews=log(1+number_of_reviews)) #avoid value unavailable for model

#Create the model1
model1 <- lm(log(price_4_nights) ~ prop_type_simplified +log_number_of_reviews +review_scores_rating ,data=listings_4)
summary(model1)

```

- Interpret the coefficient `review_scores_rating` in terms of `price_4_nights`.


- Interpret the coefficient of `prop_type_simplified` in terms of `price_4_nights`.
```{r}
###Unfinished
```


## Model2: Room type 
We want to determine if `room_type` is a significant predictor of the cost for 4 nights, given everything else in the model. 
Fit a regression model called model2 that includes all of the explananatory variables in `model1` plus `room_type`

```{r}

model2 <- lm(log(price_4_nights) ~ prop_type_simplified+log_number_of_reviews+review_scores_rating + room_type, data = listings_4)
summary(model2)
```

```{r}
###Unfinished 
```


## Model 3: Bedrooms, beds and accomodates
We want to further determine whether the number of`bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`.

```{r}
#Create the model to test the prediction effect of the number of bedrooms, beds, and the size of the house
model3_1 <- lm(log(price_4_nights) ~ bedrooms + beds + accommodates, data = listings_4)

model3_2 <- lm(log(price_4_nights) ~ prop_type_simplified+log_number_of_reviews+review_scores_rating + room_type+bedrooms + beds + accommodates, data = listings_4)

```


```{r}
summary(model3_1)
```

```{r}
summary(model3_2)
```


```{r}
# Check for colinearity
library(car)
vif(model3_2)
```


```{r}
###Unfinished interpretation
```

### Model4: Superhosts
We want to explore whether the superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables. 

```{r}
model4_1 <- lm(log(price_4_nights) ~ host_is_superhost, data = listings_4)

model4_2 <- lm(log(price_4_nights) ~ host_is_superhost, data = listings_4)

```



1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?


1. For all cities, there are 3 variables that relate to neighbourhoods: `neighbourhood`, `neighbourhood_cleansed`, and `neighbourhood_group_cleansed`. There are typically more than 20 neighbourhoods in each city, and it wouldn't make sense to include them all in your model. Use your city knowledge, or ask someone with city knowledge, and see whether you can group neighbourhoods together so the majority of listings falls in fewer (5-6 max) geographical areas. You would thus need to create a new categorical variabale `neighbourhood_simplified` and determine whether location is a predictor of `price_4_nights`


1. What is the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables?


## Diagnostics, collinearity, summary tables

As you keep building your models, it makes sense to:

1. Check the residuals, using `autoplot(model_x)`
1. As you start building models with more explanatory variables, make sure you use `car::vif(model_x)`` to calculate the **Variance Inflation Factor (VIF)** for your predictors and determine whether you have colinear variables. A general guideline is that a VIF larger than 5 or 10 is large, and your model may suffer from collinearity. Remove the variable in question and run your model again without it.



1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.


1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)



```{r}
# Determining the most common type of rooms
listings_room<-favstats(price~property_type,data=listings_4) %>% 
  filter(n>=200) %>% 
  arrange(desc(n))

top_rooms=listings_room$property_type ##extracting the top rooms

listings_4_room<-listings2 %>% 
  filter(property_type==top_rooms) %>% 
  filter(accommodates>=2) %>% ##taking the rooms that fit more than 2 people
  group_by(property_type) %>% 
  summarize(price=price)

# Plot density of log(price_4_nights) per room type
ggplot(listings_4_room,aes(x=log(price),fill=property_type))+
  geom_density(alpha=0.3) +    
  labs(      
      title = "Density plot for prices for 4 nights by property type",
      x = "price per night (log)",
      y = "density") + 
      theme_classic() + 
    NULL

```


```{r}
##Is the price of private room significantly lower?
listings_private<-listings_4 %>% 
  mutate(is_private_room = ifelse(property_type=="Private room in rental unit", "yes","no")) #creating categories

t.test(price ~ is_private_room, data = listings_private)
```
The t-value is way above 2 ant the p value is lower than 10^(-5). We can conclude that  private rooms seem to have a lower renting price. 
```{r}

#Using above dataset for the confidence interval calculations
formula_ci <- listings_4_room%>% 
  
  #Calculate weight's summary statistics for people exercising at least 3 times a week 
  
  # calculate mean, SD, count, SE, lower/upper 95% CI
  summarise(
    average_price=mean(price,na.rm=TRUE), #Mean, we choose to ignore any missing values by setting the 'na.rm = TRUE'
            
    sd_price=sd(price,na.rm=TRUE), #Standard Deviation
            
    count= n(), #Observations
           
    t_critical = qt(0.975,count-1), #T-Critical at 95% Confidence Interval and these observations
            
    se_price=sd_price/sqrt(count), #Standard Error 
           
    margin_of_error= t_critical*se_price, #Margin of Error
            
    price_low= average_price - margin_of_error, #Lower interval
            
    price_high= average_price + margin_of_error) #Upper Interval 

formula_ci

ggplot(formula_ci, aes(x=average_price, y=property_type, color=property_type)) +

#geom_errorbar function allows us to show the two bars with confidence intervals

geom_errorbar(aes(xmin=price_low, xmax=price_high),width = 0.1, size=0.5)+ 
  
geom_point(aes(x=average_price),size=1)+

  
theme_bw() +
  
theme(legend.position = "none",axis.title.y=element_blank())+
  
  labs(title = "CI for average price per room type",
       subtitle = "95% confidence intervals overlap",
       x = "Average Price"
       ) +
  NULL
```
The property type seems to have a significant effect on prices. The length of the intervals mainly vary due to the differences in sample size. The most common property type (Entire rental unit) has a small interval because it has the larger sample. We can estimate quite aaccuratly the average price in this category.

```{r}
favstats(price_4_nights~host_is_superhost,data=listings_4)
```
```{r}
t.test(price_4_nights ~ host_is_superhost, data = listings_4)
```

```{r}
favstats(price_4_nights~accommodates,data=listings_4)
```


```{r}

#Using above dataset for the confidence interval calculations
formula_ci <- listings_4 %>% 
  filter(accommodates<=8) %>% 
  filter(accommodates>=1) %>% 
  group_by(accommodates) %>% 
  
  #Calculate weight's summary statistics for people exercising at least 3 times a week 
  
  # calculate mean, SD, count, SE, lower/upper 95% CI
  summarise(
    average_price=mean(price,na.rm=TRUE), #Mean, we choose to ignore any missing values by setting the 'na.rm = TRUE'
            
    sd_price=sd(price,na.rm=TRUE), #Standard Deviation
            
    count= n(), #Observations
           
    t_critical = qt(0.975,count-1), #T-Critical at 95% Confidence Interval and these observations
            
    se_price=sd_price/sqrt(count), #Standard Error 
           
    margin_of_error= t_critical*se_price, #Margin of Error
            
    price_low= average_price - margin_of_error, #Lower interval
            
    price_high= average_price + margin_of_error) #Upper Interval 

formula_ci

ggplot(formula_ci, aes(x=average_price, y=accommodates, color=accommodates)) +

#geom_errorbar function allows us to show the two bars with confidence intervals

geom_errorbar(aes(xmin=price_low, xmax=price_high),width = 0.1, size=0.5)+ 
  
geom_point(aes(x=average_price),size=1)+

  
theme_bw() +
  
theme(legend.position = "none",axis.title.y=element_blank())+
  
  labs(title = "CI for average price per room type",
       subtitle = "95% confidence intervals overlap",
       x = "Average Price"
       ) +
  NULL


```

```{r}
t.test(price_4_nights ~ license, data = listings_4)
```

```{r}
#higher price in De Pijp?

listings_4_pijp<-listings_4 %>% 
  mutate(is_in_pjip = ifelse(neighbourhood_cleansed=="De Pijp - Rivierenbuurt", "yes","no"))

t.test(price_4_nights ~ is_in_pjip, data = listings_4_pijp)


```
```{r}

listings_instant<-listings2 %>% 
  select("price","instant_bookable")

listings_instant

favstats(price~instant_bookable,data=listings_instant)

t_test(price~instant_bookable,data=listings_instant)
```


## Further variables/questions to explore on our own

Our dataset has many more variables, so here are some ideas on how you can extend your analysis

1. Are the number of `bathrooms`, `bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`? Or might these be co-linear variables?
1. Do superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables?
1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?
1. For all cities, there are 3 variables that relate to neighbourhoods: `neighbourhood`, `neighbourhood_cleansed`, and `neighbourhood_group_cleansed`. There are typically more than 20 neighbourhoods in each city, and it wouldn't make sense to include them all in your model. Use your city knowledge, or ask someone with city knowledge, and see whether you can group neighbourhoods together so the majority of listings falls in fewer (5-6 max) geographical areas. You would thus need to create a new categorical variabale `neighbourhood_simplified` and determine whether location is a predictor of `price_4_nights`
1. What is the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables?


## Diagnostics, collinearity, summary tables

As you keep building your models, it makes sense to:

1. Check the residuals, using `autoplot(model_x)`
1. As you start building models with more explanatory variables, make sure you use `car::vif(model_x)`` to calculate the **Variance Inflation Factor (VIF)** for your predictors and determine whether you have colinear variables. A general guideline is that a VIF larger than 5 or 10 is large, and your model may suffer from collinearity. Remove the variable in question and run your model again without it.



1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.
1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)








# Deliverables


- By midnight on Monday 18 Oct 2021, you must upload on Canvas a short presentation (max 4-5 slides) with your findings, as some groups will be asked to present in class. You should present your Exploratory Data Analysis, as well as your best model. In addition, you must upload on Canvas your final report, written  using R Markdown to introduce, frame, and describe your story and findings. You should include the following in the memo:

1. Executive Summary: Based on your best model, indicate the factors that influence `price_4_nights`.
This should be written for an intelligent but non-technical audience. All
other sections can include technical writing.
2. Data Exploration and Feature Selection: Present key elements of the data, including tables and
graphs that help the reader understand the important variables in the dataset. Describe how the
data was cleaned and prepared, including feature selection, transformations, interactions, and
other approaches you considered.
3. Model Selection and Validation: Describe the model fitting and validation process used. State
the model you selected and why they are preferable to other choices.
4. Findings and Recommendations: Interpret the results of the selected model and discuss
additional steps that might improve the analysis
  
  

Remember to follow R Markdown etiquette rules and style; don't have the Rmd output extraneous messages or warnings, include summary tables in nice tables (use `kableExtra`), and remove any placeholder texts from past Rmd templates; in other words, (i.e. I don't want to see stuff I wrote in your final report.)
  
  
# Rubric

Your work will be assessed on a rubric which you can find here


```{r rubric, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "rubric.png"), error = FALSE)
```


# Acknowledgements

- The data for this project is from [insideairbnb.com](insideairbnb.com)




